agent:  ???        # Agent type [bopt-gmm, dbopt]
prior_range: 0.15  # Range to vary the prior weights by [-v, v]
mean_range:  0.10  # Range to vary the means in percentage by [-v, v]
sigma_range: 0.0   # Range to vary the (covariance) in percentage by [-v, v]
early_tell: 8      # Min number of steps to inform the optimizer after
late_tell: 100000  # Max number of steps to inform the optimizer after
reward_processor: "mean"
base_estimator: "GP"
initial_p_gen: "random"
n_initial_points: 10
acq_func: "EI"
acq_optimizer: "hpo"
gripper_command: 0.0
budget_min: 5
budget_max: 10
n_trials: 10
opt_dims: null
num_training_cycles: 50
num_episode_steps: 600
incumbent_eval:
  eval_after: 1000
  episodes: 20
  new_model_every: 10
  improvement_expectation: 0.65

gmm:
  model: ???
  type:  ???
  force_norm: ???
  var_adjustment: 0  # Value added to the variances of the GMM to avoid numerical issues
