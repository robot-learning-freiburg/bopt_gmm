{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from tqdm    import tqdm\n",
    "from typing  import Iterable\n",
    "import random\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HATCH\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_bopt_exp_sd/')\n",
    "# STAT_PATTERN   = 'is_sd_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_sliding_door.csv')\n",
    "# OUT_PREFIX     = 'bopt_hatch'\n",
    "# METHOD_NAME    = 'bopt'\n",
    "\n",
    "# DOOR\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_bopt_exp_door/')\n",
    "# STAT_PATTERN   = 'is_door_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_door.csv')\n",
    "# OUT_PREFIX     = 'bopt_door'\n",
    "# METHOD_NAME    = 'bopt'\n",
    "\n",
    "# REAL HATCH\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_bopt_gmm_exp_rdrawer_super_narrow_shorter/')\n",
    "# STAT_PATTERN   = 'is_rdrawer_p3_hpo_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_real_drawer.csv')\n",
    "# OUT_PREFIX     = 'bopt_real_drawer'\n",
    "# METHOD_NAME    = 'bopt'\n",
    "\n",
    "# REAL DOOR\n",
    "STAT_DIRECTORY = Path('/home/aroefer/bopt_gmm_exp_rdoor_super_narrow_shorter/')\n",
    "STAT_PATTERN   = 'is_rdoor_p3_hpo_*'\n",
    "DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_real_door.csv')\n",
    "OUT_PREFIX     = 'bopt_real_door'\n",
    "METHOD_NAME    = 'bopt'\n",
    "\n",
    "# SACGMM - DOOR\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_door/')\n",
    "# STAT_PATTERN   = 'is_door_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_door'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM - REAL DRAWER\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_rdrawer_super_narrow_shorter/')\n",
    "# STAT_PATTERN   = 'is_rdrawer_p3_hpo_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_real_drawer.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_real_drawer'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM - REAL DOOR\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_rdoor_super_narrow_shorter/')\n",
    "# STAT_PATTERN   = 'is_rdoor_p3_hpo_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_real_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_real_door'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM - HATCH\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_sd/')\n",
    "# STAT_PATTERN   = 'is_sd_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_sliding_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_hatch'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM RPB - DOOR\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_door/')\n",
    "# STAT_PATTERN   = 'is_door_rpb_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_rpb_door'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM RPB - HATCH\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_sd/')\n",
    "# STAT_PATTERN   = 'is_sd_rpb_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_sliding_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_rpb_hatch'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM RPB GL70 - DOOR\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_door/')\n",
    "# STAT_PATTERN   = 'is_door_rpb_gl70_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_rpb_door_gl70'\n",
    "# METHOD_NAME    = 'sacgmm'\n",
    "\n",
    "# SACGMM RPB GL70 - HATCH\n",
    "# STAT_DIRECTORY = Path('/home/aroefer/icra_sacgmm_exp_sd/')\n",
    "# STAT_PATTERN   = 'is_sd_rpb_gl70_p5_*'\n",
    "# DF_BASELINES   = pd.read_csv('/home/aroefer/rl_ws/src/bopt_gmm/data/baselines_sliding_door.csv')\n",
    "# OUT_PREFIX     = 'sacgmm_rpb_hatch_gl70'\n",
    "# METHOD_NAME    = 'sacgmm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AccuracyStat:\n",
    "    dir_prefix  : str\n",
    "    data_points : dict\n",
    "    components  : int   = 3\n",
    "    prior       : float = 0.0\n",
    "    mean        : float = 0.0\n",
    "    covar       : float = 0.0\n",
    "    noise       : float = None\n",
    "    means       : list  = None\n",
    "    cvars       : list  = None\n",
    "    cvar_type   : str   = None\n",
    "    baseline    : float = 0.0\n",
    "    last_optimization : set = None\n",
    "    num_incumbents : dict = None\n",
    "\n",
    "def collect_ic_data(files : Iterable[Path], base_lines : dict, base_value=0.0):\n",
    "    data_points = {}\n",
    "\n",
    "    perf_base = base_value\n",
    "    noise = None\n",
    "    components = None\n",
    "    opt_episode_step = {}\n",
    "\n",
    "    # Figure out the number of samples\n",
    "    samples = set(int(f.parent.name.split('_')[-2]) for f in files)\n",
    "    sample_idx = dict(zip(samples, range(len(samples))))\n",
    "    directory_prefix = '_'.join(files[0].parent.name.split('_')[:-2])\n",
    "\n",
    "    final_perf = {}\n",
    "\n",
    "    incumbent_count = {}\n",
    "\n",
    "    # Collect base array\n",
    "    for f in files:\n",
    "        sample = int(f.parent.name.split('_')[-2])\n",
    "        s_idx  = sample_idx[sample]\n",
    "        if noise is None:\n",
    "            components = int([p[-1] for p in f.parent.name.split('_') if len(p) == 2 and p[0] == 'p'][0])\n",
    "\n",
    "            try:\n",
    "                df_ic = pd.read_csv(f.parent / f'{METHOD_NAME}_initial_conditions.csv')\n",
    "                opt_substeps = {bs: df_ic[df_ic.bopt_step == bs].substep.max() for bs in df_ic.bopt_step.unique()}\n",
    "                epsiode_counter = 0\n",
    "                for bs, ss in sorted(opt_substeps.items()):\n",
    "                    opt_episode_step[bs] = epsiode_counter\n",
    "                    epsiode_counter += ss\n",
    "            except pd.errors.EmptyDataError:\n",
    "                if METHOD_NAME != 'sacgmm':\n",
    "                    raise Exception(f'CSV \"{f.parent / f\"{METHOD_NAME}_initial_conditions.csv\"}\" seems to be empty.')\n",
    "\n",
    "            with open(f.parent / 'config.yaml') as cf:\n",
    "                config = yaml.safe_load(cf)\n",
    "            model = config['bopt_agent']['gmm']['model']\n",
    "\n",
    "            try:\n",
    "                noise = config['env']['noise']['position']['variance']\n",
    "            except KeyError:\n",
    "                noise = 0.0\n",
    "            if model in base_lines:\n",
    "                perf_base = base_lines[model][noise]\n",
    "\n",
    "        try:\n",
    "            df  = pd.read_csv(f)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        idx = int(f.name.split('_')[-2])\n",
    "        if idx not in data_points:\n",
    "            data_points[idx] = [None] * len(samples)\n",
    "        \n",
    "        if idx not in incumbent_count:\n",
    "            incumbent_count[idx] = 0\n",
    "        \n",
    "        incumbent_count[idx] += 1\n",
    "\n",
    "        if sample not in final_perf:\n",
    "            final_perf[sample] = 0 \n",
    "\n",
    "        final_perf[sample] = max(final_perf[sample], idx)\n",
    "\n",
    "        data_points[idx][s_idx] = df.success.mean()\n",
    "    \n",
    "    sorted_keys = sorted(data_points.keys())\n",
    "    for x in range(len(sorted_keys)):\n",
    "        if x == 0:\n",
    "            data_points[sorted_keys[x]] = [v if v is not None else perf_base for v in data_points[sorted_keys[x]]]\n",
    "        else:\n",
    "            data_points[sorted_keys[x]] = [v if v is not None else data_points[sorted_keys[x-1]][y] for y, v in enumerate(data_points[sorted_keys[x]])]\n",
    "\n",
    "    if METHOD_NAME == 'sacgmm':\n",
    "        opt_episode_step = dict(zip(sorted_keys, sorted_keys))\n",
    "\n",
    "    incumbent_count = {opt_episode_step[k]: v for k, v in incumbent_count.items()}\n",
    "\n",
    "    data_points = {opt_episode_step[k]: v for k, v in data_points.items()}\n",
    "\n",
    "    final_perf = {opt_episode_step[v] for v in final_perf.values()}\n",
    "\n",
    "    cvars = config['bopt_agent']['opt_dims']['cvars'] if config['bopt_agent']['opt_dims']['cvars'] is not None else {'nary': []}\n",
    "\n",
    "    return AccuracyStat(directory_prefix,\n",
    "                        data_points,\n",
    "                        components,\n",
    "                        config['bopt_agent']['prior_range'],\n",
    "                        config['bopt_agent']['mean_range'],\n",
    "                        config['bopt_agent']['sigma_range'],\n",
    "                        noise,\n",
    "                        config['bopt_agent']['opt_dims']['means'],\n",
    "                        cvars['nary'],\n",
    "                        cvars['type'] if 'type' in cvars else '',\n",
    "                        perf_base,\n",
    "                        final_perf,\n",
    "                        incumbent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = set()\n",
    "\n",
    "for d in STAT_DIRECTORY.glob(STAT_PATTERN):\n",
    "    parts = d.name.split('_')\n",
    "    try:\n",
    "        int(parts[-2])\n",
    "        parts[-2] = '*'\n",
    "        patterns.add('_'.join(parts) + '/eval_*_ic.csv')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(len(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {m: dict(DF_BASELINES[DF_BASELINES.model == m][['noise', 'accuracy']].to_numpy()) \n",
    "             for m in DF_BASELINES.model.unique()}\n",
    "print(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data   = [] \n",
    "data_names = []\n",
    "data_by_hash = {}\n",
    "\n",
    "for p in tqdm(patterns, desc='Processing patters'):\n",
    "    files = list(STAT_DIRECTORY.glob(p))\n",
    "    if len(files) > 0:\n",
    "        all_data.append(collect_ic_data(files, baselines))\n",
    "        data_names.append(Path(p.replace('_*', '')).parent.name)\n",
    "        dhash = Path(p.replace('_*', '')).parent.name.split('_')[-1]\n",
    "        data_by_hash[dhash] = all_data[-1]\n",
    "    else:\n",
    "        print(f'Pattern \"{p}\" yielded no files.')\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data[0].data_points[sorted(all_data[0].data_points.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_var_plot(ax, data, color, label):\n",
    "    x_coords = sorted(data.keys())\n",
    "    d        = np.vstack([data[k] for k in x_coords])\n",
    "    means_ps = np.mean(d, axis=1)\n",
    "    stds_ps  = np.std(d, axis=1)\n",
    "    ax.plot(x_coords, means_ps, label=label, c=color)\n",
    "    ax.fill_between(x_coords, means_ps-stds_ps, means_ps+stds_ps, alpha=0.3, facecolor=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.array([['#12DB00', '#70F20C', '#B8E80C', '#0CF23E', '#0CE879'],\n",
    "                   ['#DB6300', '#F2520C', '#E82F0C', '#F2940C', '#E8A40C'],\n",
    "                   ['#42CEF5', '#31DED5', '#37FAB9', '#318BDE', '#3769FA'],\n",
    "                   ['#F4D221', '#DEA814', '#FAA717', '#DED114', '#DFFA17'],\n",
    "                   ['#F51D4F', '#DE10A7', '#DD12FA', '#DE2010', '#FA4612'],\n",
    "                   ['#7C15F5', '#3209DE', '#0A1CFA', '#A609DE', '#FA0AF5'],\n",
    "                   ['#1B3EF5', '#0D67DE', '#0FB2FA', '#220DDE', '#670FFA']])\n",
    "\n",
    "COLORS_RANDOM = COLORS.flatten().copy() \n",
    "random.shuffle(COLORS.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in all_data:\n",
    "    print(a.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_as(a : AccuracyStat):\n",
    "    return f'$\\omega = {a.prior}, \\mu = {a.mean}, \\Sigma = {a.covar}$ {\"\".join([m[0] for m in a.means])} {a.cvar_type}'\n",
    "\n",
    "noise_filter = 0.00\n",
    "\n",
    "filtered_data = [(str_as(a), a) for a in all_data if a.noise == noise_filter]\n",
    "\n",
    "components = sorted({a.components for _, a in filtered_data})\n",
    "data_by_components = {c: [(label, a) for label, a in filtered_data if a.components == c] for c in components}\n",
    "\n",
    "for c, data in data_by_components.items():\n",
    "    n_cols = int(math.ceil(len(data) / 3))\n",
    "    fig, axes = plt.subplots(n_cols, 3, figsize=((6 * 3) / 2.54, (5 * n_cols) / 2.54), layout='constrained', dpi=200)\n",
    "\n",
    "    legend = {}\n",
    "    colors = {}\n",
    "\n",
    "    for x, ((label, ac_stat), ax) in enumerate(zip(sorted(data, key=lambda t: t[0]), axes.flatten())):  # type data: AccuracyStat\n",
    "        if x % 3 == 0:\n",
    "            ax.set_yticks(np.linspace(0.0, 1.0, 6))\n",
    "            ax.set_ylabel('Accuracy')\n",
    "        else:\n",
    "            ax.set_yticks(np.linspace(0.0, 1.0, 6), [])\n",
    "\n",
    "        if label not in colors:\n",
    "            colors[label] = COLORS.T.flatten()[len(colors)]\n",
    "\n",
    "        draw_var_plot(ax, ac_stat.data_points, colors[label], label)\n",
    "\n",
    "        ax.set_xlabel('Episodes')\n",
    "        ax.set_xticks(np.linspace(0, 500, 6))\n",
    "        ax.grid(True)\n",
    "        # if x == 0:\n",
    "        #     ax.legend(bbox_to_anchor=(0., -.92, 2.2, .102),  loc='lower left',\n",
    "        #                   ncols=3, mode=\"expand\", borderaxespad=0)\n",
    "        ax.set_ylim((0 - 0.05, 1.0 + 0.05))\n",
    "        ax.set_xlim((0 - 2, 500 + 2))\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        legend.update(dict(zip(labels, handles)))\n",
    "\n",
    "        ax.hlines(ac_stat.baseline, *ax.get_xlim(), color='#ee3322', linestyle='dotted')\n",
    "        \n",
    "        if METHOD_NAME == 'bopt':\n",
    "            total_inc = max(ac_stat.num_incumbents.values())\n",
    "            for t, count in ac_stat.num_incumbents.items():\n",
    "                ax.vlines(t, 0, count / total_inc, zorder=0)\n",
    "        \n",
    "\n",
    "    fig.suptitle(f'Scenario: \"{OUT_PREFIX}\"   Method: ${METHOD_NAME}$   $k = {c}$   Noise: $\\sigma = {noise_filter}$')\n",
    "    fig.legend(legend.values(), legend.keys(), loc='outside lower center', ncols=2)\n",
    "    fig.savefig(f'plots/{OUT_PREFIX}_p{c}_n{int(noise_filter*100):02d}.png')\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dn, ac in zip(data_names, all_data):\n",
    "    pd.DataFrame(np.vstack([(x, np.mean(d), np.std(d)) for x, d in sorted(ac.data_points.items())]),\n",
    "                 columns=['x', 'y', 'std']).to_csv(f'data/{METHOD_NAME}_{dn}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 'k omega mu sigma mu_dim sigma_type noise accuracy episode_count baseline mean_final std_final'.split(' ')\n",
    "\n",
    "data = []\n",
    "\n",
    "for a in all_data:  \n",
    "    a = a # type: AccuracyStat\n",
    "    last_data = sorted(a.data_points.keys())[-1]\n",
    "    data.append([a.components, a.prior, a.mean, a.covar, ' '.join(a.means), a.cvar_type, a.noise,\n",
    "                 np.mean(a.data_points[last_data]), last_data, a.baseline, np.mean(list(a.last_optimization)),\n",
    "                 np.std(list(a.last_optimization))])\n",
    "\n",
    "pd.DataFrame(data, columns=columns).to_csv(f'plots/{OUT_PREFIX}_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data_by_headers    = {}\n",
    "incumbent_data_by_headers = {}\n",
    "\n",
    "for d in tqdm(list(STAT_DIRECTORY.glob(STAT_PATTERN)), desc='Reading bopt configs...'):\n",
    "    dhash = d.name.split('_')[-1]\n",
    "\n",
    "    ac_stat = data_by_hash[dhash]\n",
    "\n",
    "    try:\n",
    "        df_config = pd.read_csv(d / 'bopt_configs.csv')\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "    # Relabel eigen updates based on type\n",
    "    if ac_stat.cvar_type == 'rotation':\n",
    "        columns = [c if c[:2] != 'e_' else 'rot_' + c[2:] for c in df_config.columns]\n",
    "    else:\n",
    "        columns = df_config.columns\n",
    "\n",
    "    header_key = ','.join(columns)\n",
    "    if header_key not in config_data_by_headers:\n",
    "        config_data_by_headers[header_key] = []\n",
    "    \n",
    "    config_data_by_headers[header_key].append(df_config.to_numpy())\n",
    "\n",
    "    df_config = pd.read_csv(d / 'bopt_incumbents.csv')\n",
    "    # Relabel eigen updates based on type\n",
    "    if ac_stat.cvar_type == 'rotation':\n",
    "        columns = [c if c[:2] != 'e_' else 'rot_' + c[2:] for c in df_config.columns]\n",
    "    else:\n",
    "        columns = df_config.columns\n",
    "\n",
    "    header_key = ','.join(columns)\n",
    "    if header_key not in incumbent_data_by_headers:\n",
    "        incumbent_data_by_headers[header_key] = []\n",
    "    \n",
    "    incumbent_data_by_headers[header_key].append(df_config.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(config_data_by_headers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_values = {'e' : 1.0, 'mean': 0.0, 'weight': 0.0, 'rot': 0.0}\n",
    "\n",
    "def join_tables(header_data_dict : dict, neutral_values: dict) -> pd.DataFrame:\n",
    "    joint_header = list(set(sum([k.split(',') for k in header_data_dict.keys()], [])))\n",
    "\n",
    "    full_data = []\n",
    "\n",
    "    for c, d in header_data_dict.items():\n",
    "        c = c.split(',')\n",
    "        d = np.vstack(d)\n",
    "        \n",
    "        new_data = np.ones((d.shape[0], len(joint_header)))\n",
    "\n",
    "        for x, column in enumerate(joint_header):\n",
    "            try:\n",
    "                ox = c.index(column)\n",
    "                new_data[:, x] = d[:, ox]\n",
    "            except ValueError:\n",
    "                prefix = column.split('_')[0]\n",
    "                new_data[:, x] = neutral_values[prefix]\n",
    "        \n",
    "        full_data.append(new_data)\n",
    "    \n",
    "    return pd.DataFrame(np.vstack(full_data), columns=joint_header)\n",
    "\n",
    "join_tables(config_data_by_headers, neutral_values).to_csv(f'data/{OUT_PREFIX}_configs.csv', index=False)\n",
    "join_tables(incumbent_data_by_headers, neutral_values).to_csv(f'data/{OUT_PREFIX}_incumbents.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_eigen = []\n",
    "final_acc_rot   = []\n",
    "final_acc_mean  = []\n",
    "final_acc_prior = []\n",
    "final_acc_mean_eigen = []\n",
    "final_acc_mean_rot   = []\n",
    "\n",
    "noise_filter = 0.03\n",
    "\n",
    "\n",
    "for a in all_data: # type: AccuracyStat\n",
    "    if noise_filter is not None and a.noise != noise_filter:\n",
    "        continue\n",
    "    if a.prior != 0.0 and a.mean == 0.0 and a.covar == 0.0:\n",
    "        final_acc_prior.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar == 0.0:\n",
    "        final_acc_mean.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "    elif a.prior != 0.0 and a.mean == 0.0 and a.covar != 0.0 and a.cvar_type == 'eigen':\n",
    "        final_acc_eigen.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "    elif a.prior != 0.0 and a.mean == 0.0 and a.covar != 0.0 and a.cvar_type == 'rotation':\n",
    "        final_acc_rot.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar != 0.0 and a.cvar_type == 'eigen':\n",
    "        final_acc_mean_eigen.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar != 0.0 and a.cvar_type == 'rotation':\n",
    "        final_acc_mean_rot.append(np.mean(a.data_points[max(a.data_points.keys())]))\n",
    "\n",
    "print(f'Mean: {np.mean(final_acc_mean )}')\n",
    "print(f'Eigen: {np.mean(final_acc_eigen)}')\n",
    "print(f'Rot: {np.mean(final_acc_rot  )}')\n",
    "print(f'Mean + Eigen: {np.mean(final_acc_mean_eigen)}')\n",
    "print(f'Mean + Rot: {np.mean(final_acc_mean_rot  )}')\n",
    "\n",
    "print()\n",
    "\n",
    "perf_reached_after_eigen = []\n",
    "perf_reached_after_rot   = []\n",
    "perf_reached_after_mean  = []\n",
    "perf_reached_after_prior = []\n",
    "perf_reached_after_mean_eigen = []\n",
    "perf_reached_after_mean_rot   = []\n",
    "threshold = 0.6\n",
    "\n",
    "for a in all_data: # type: AccuracyStat\n",
    "    if noise_filter is not None and a.noise != noise_filter:\n",
    "        continue\n",
    "\n",
    "    for s, d in sorted(a.data_points.items()):\n",
    "        if np.mean(d) >= threshold:\n",
    "            break\n",
    "    else:\n",
    "        s = 500\n",
    "\n",
    "    if a.prior != 0.0 and a.mean == 0.0 and a.covar == 0.0:\n",
    "        perf_reached_after_prior.append(s)\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar == 0.0:\n",
    "        perf_reached_after_mean.append(s)\n",
    "    elif a.prior != 0.0 and a.mean == 0.0 and a.covar != 0.0 and a.cvar_type == 'eigen':\n",
    "        perf_reached_after_eigen.append(s)\n",
    "    elif a.prior != 0.0 and a.mean == 0.0 and a.covar != 0.0 and a.cvar_type == 'rotation':\n",
    "        perf_reached_after_rot.append(s)\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar != 0.0 and a.cvar_type == 'eigen':\n",
    "        perf_reached_after_mean_eigen.append(s)\n",
    "    elif a.prior != 0.0 and a.mean != 0.0 and a.covar != 0.0 and a.cvar_type == 'rotation':\n",
    "        perf_reached_after_mean_rot.append(s)\n",
    "\n",
    "print(f'Mean accuracy >= {threshold} after: {np.mean(perf_reached_after_mean )}')\n",
    "print(f'Eigen accuracy >= {threshold} after: {np.mean(perf_reached_after_eigen)}')\n",
    "print(f'Rot accuracy >= {threshold} after: {np.mean(perf_reached_after_rot  )}')\n",
    "print(f'Mean + Eigen accuracy >= {threshold} after: {np.mean(perf_reached_after_mean_eigen)}')\n",
    "print(f'Mean + Rot accuracy >= {threshold} after: {np.mean(perf_reached_after_mean_rot  )}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
